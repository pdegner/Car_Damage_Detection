{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning: Whole or Damaged?\n",
    "\n",
    "This is all done on black and white images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "# from imageai.Prediction.Custom import ModelTraining\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "Create the following datasets:\n",
    "- train_data: unfiltered training images\n",
    "- train_data_f: bilateral filtered training images\n",
    "- train_labels: labels for training images\n",
    "- test_data: unfiltered test images\n",
    "- test_data_f: bilateral filtered test images\n",
    "- test_labels: labels for test images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set up training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "damage_dir = cwd + '/data/training/00-damage/'\n",
    "whole_dir = cwd + '/data/training/01-whole/'\n",
    "targetdir = cwd +  '/data/training/clustered/'\n",
    "damage_move_dir = cwd + '/data_blur/training/damaged/'\n",
    "whole_move_dir = cwd + '/data_blur/training/whole/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Status: 920 / 920\r"
     ]
    }
   ],
   "source": [
    "# Load the images for original data\n",
    "damage_image_list = []\n",
    "damage_filelist = glob.glob(damage_dir + '*.JPEG') + glob.glob(damage_dir + '*.jpg')\n",
    "damage_filelist.sort()\n",
    "for i, imagepath in enumerate(damage_filelist):\n",
    "    print(\"    Status: %s / %s\" %(i+1, len(damage_filelist)), end=\"\\r\")\n",
    "    image = imread(imagepath,as_gray=True)\n",
    "    image = resize(image, (224,224)) \n",
    "    features = np.reshape(image, (224*224))\n",
    "    damage_image_list.append(features)\n",
    "    \n",
    "whole_image_list = []\n",
    "whole_filelist = glob.glob(whole_dir + '*.JPEG') + glob.glob(whole_dir + '*.jpg')\n",
    "whole_filelist.sort()\n",
    "for i, imagepath in enumerate(whole_filelist):\n",
    "    print(\"    Status: %s / %s\" %(i+1, len(whole_filelist)), end=\"\\r\")\n",
    "    image = imread(imagepath,as_gray=True)\n",
    "    image = resize(image, (224,224)) \n",
    "    features = np.reshape(image, (224*224))\n",
    "    whole_image_list.append(features)\n",
    "    \n",
    "# Create Labels\n",
    "damage_label = [1 for im in damage_image_list]\n",
    "whole_label = [0 for im in whole_image_list]\n",
    "\n",
    "# Combine data\n",
    "train_data = damage_image_list + whole_image_list\n",
    "train_labels = damage_label + whole_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Status: 920 / 920\r"
     ]
    }
   ],
   "source": [
    "# Load the images for bilateral filtered data\n",
    "damage_image_list_f = []\n",
    "damage_filelist_f = glob.glob(damage_move_dir + '*.JPEG') + glob.glob(damage_move_dir + '*.jpg')\n",
    "damage_filelist_f.sort()\n",
    "for i, imagepath in enumerate(damage_filelist_f):\n",
    "    print(\"    Status: %s / %s\" %(i+1, len(damage_filelist_f)), end=\"\\r\")\n",
    "    image = imread(imagepath,as_gray=True)\n",
    "    image = resize(image, (224,224)) \n",
    "    features = np.reshape(image, (224*224))\n",
    "    damage_image_list_f.append(features)\n",
    "    \n",
    "whole_image_list_f = []\n",
    "whole_filelist_f = glob.glob(whole_move_dir + '*.JPEG') + glob.glob(whole_move_dir + '*.jpg')\n",
    "whole_filelist_f.sort()\n",
    "for i, imagepath in enumerate(whole_filelist_f):\n",
    "    print(\"    Status: %s / %s\" %(i+1, len(whole_filelist_f)), end=\"\\r\")\n",
    "    image = imread(imagepath,as_gray=True)\n",
    "    image = resize(image, (224,224)) \n",
    "    features = np.reshape(image, (224*224))\n",
    "    whole_image_list_f.append(features)\n",
    "\n",
    "# Combine data\n",
    "train_data_f = damage_image_list_f + whole_image_list_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set up testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "damage_dir_test = cwd + '/data/validation/00-damage/'\n",
    "whole_dir_test = cwd + '/data/validation/01-whole/'\n",
    "damage_move_dir_test = cwd + '/data_blur/validation/damaged/'\n",
    "whole_move_dir_test = cwd + '/data_blur/validation/whole/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Status: 230 / 230\r"
     ]
    }
   ],
   "source": [
    "# Load the images for original testing data\n",
    "damage_image_list_t = []\n",
    "damage_filelist_t = glob.glob(damage_dir_test + '*.JPEG') + glob.glob(damage_dir_test + '*.jpg')\n",
    "damage_filelist_t.sort()\n",
    "for i, imagepath in enumerate(damage_filelist_t):\n",
    "    print(\"    Status: %s / %s\" %(i+1, len(damage_filelist_t)), end=\"\\r\")\n",
    "    image = imread(imagepath,as_gray=True)\n",
    "    image = resize(image, (224,224)) \n",
    "    features = np.reshape(image, (224*224))\n",
    "    damage_image_list_t.append(features)\n",
    "    \n",
    "whole_image_list_t = []\n",
    "whole_filelist_t = glob.glob(whole_dir_test + '*.JPEG') + glob.glob(whole_dir_test + '*.jpg')\n",
    "whole_filelist_t.sort()\n",
    "for i, imagepath in enumerate(whole_filelist_t):\n",
    "    print(\"    Status: %s / %s\" %(i+1, len(whole_filelist_t)), end=\"\\r\")\n",
    "    image = imread(imagepath,as_gray=True)\n",
    "    image = resize(image, (224,224)) \n",
    "    features = np.reshape(image, (224*224))\n",
    "    whole_image_list_t.append(features)\n",
    "\n",
    "# Combine data\n",
    "test_data = damage_image_list_t + whole_image_list_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Status: 230 / 230\r"
     ]
    }
   ],
   "source": [
    "# Load the images for bilateral filtered testing data\n",
    "damage_image_list_tf = []\n",
    "damage_filelist_tf = glob.glob(damage_move_dir_test + '*.JPEG') + glob.glob(damage_move_dir_test + '*.jpg')\n",
    "damage_filelist_tf.sort()\n",
    "for i, imagepath in enumerate(damage_filelist_tf):\n",
    "    print(\"    Status: %s / %s\" %(i+1, len(damage_filelist_tf)), end=\"\\r\")\n",
    "    image = imread(imagepath,as_gray=True)\n",
    "    image = resize(image, (224,224)) \n",
    "    features = np.reshape(image, (224*224))\n",
    "    damage_image_list_tf.append(features)\n",
    "    \n",
    "whole_image_list_tf = []\n",
    "whole_filelist_tf = glob.glob(whole_move_dir_test + '*.JPEG') + glob.glob(whole_move_dir_test + '*.jpg')\n",
    "whole_filelist_tf.sort()\n",
    "for i, imagepath in enumerate(whole_filelist_tf):\n",
    "    print(\"    Status: %s / %s\" %(i+1, len(whole_filelist_tf)), end=\"\\r\")\n",
    "    image = imread(imagepath,as_gray=True)\n",
    "    image = resize(image, (224,224)) \n",
    "    features = np.reshape(image, (224*224))\n",
    "    whole_image_list_tf.append(features)\n",
    "    \n",
    "# Create Labels\n",
    "damage_label_tf = [1 for im in damage_image_list_tf]\n",
    "whole_label_tf = [0 for im in whole_image_list_tf]\n",
    "\n",
    "# Combine data\n",
    "test_data_f = damage_image_list_tf + whole_image_list_tf\n",
    "test_labels = damage_label_tf + whole_label_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN on original vs filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy when k=5 on unfiltered data is 60.99%\n",
      "Accuracy when k=5 on filtered data is 59.64%\n",
      "Elapsed time: 119.14 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "# Fit model on unfiltered data\n",
    "knn_orig = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_orig.fit(train_data, train_labels)\n",
    "accuracy = knn_orig.score(test_data, test_labels)*100\n",
    "print(\"Accuracy when k=5 on unfiltered data is %.2f%%\" % accuracy)\n",
    "\n",
    "# Fit model on bilateral filtered data\n",
    "knn_filt = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_filt.fit(train_data_f, train_labels)\n",
    "accuracy_f = knn_filt.score(test_data_f, test_labels)*100\n",
    "print(\"Accuracy when k=5 on filtered data is %.2f%%\" % accuracy_f)\n",
    "t1 = time.time()\n",
    "print(\"Elapsed time: %.2f seconds\" % (t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing weight types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy when k=5 on unfiltered data is 61.66%\n",
      "Accuracy when k=5 on filtered data is 60.31%\n",
      "Elapsed time: 118.22 seconds\n"
     ]
    }
   ],
   "source": [
    "t0= time.time()\n",
    "# Fit model on unfiltered data\n",
    "# Points are weighted on the inverse of their distance\n",
    "knn_orig = KNeighborsClassifier(n_neighbors=5, weights = 'distance')\n",
    "knn_orig.fit(train_data, train_labels)\n",
    "accuracy_d = knn_orig.score(test_data, test_labels)*100\n",
    "print(\"Accuracy when k=5 on unfiltered data is %.2f%%\" % accuracy_d)\n",
    "\n",
    "# Fit model on bilateral filtered data\n",
    "knn_filt = KNeighborsClassifier(n_neighbors=5, weights = 'distance')\n",
    "knn_filt.fit(train_data_f, train_labels)\n",
    "accuracy_fd = knn_filt.score(test_data_f, test_labels)*100\n",
    "print(\"Accuracy when k=5 on filtered data is %.2f%%\" % accuracy_fd)\n",
    "t1 = time.time()\n",
    "print(\"Elapsed time: %.2f seconds\" % (t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How much did accuracy change?\n",
      "\tFor unfiltered data: 0.6726%\n",
      "\tFor filtered data: 0.6726%\n",
      "The change is the same for both models: True\n"
     ]
    }
   ],
   "source": [
    "print(\"How much did accuracy change?\")\n",
    "print(\"\\tFor unfiltered data: %.4f%%\\n\\tFor filtered data: %.4f%%\" %(accuracy_d-accuracy, accuracy_fd-accuracy_f))\n",
    "print(\"The change is the same for both models: %s\" %((accuracy_d-accuracy==accuracy_fd-accuracy_f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing values for k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy when k=1 on unfiltered data is 57.85%\n",
      "Accuracy when k=3 on unfiltered data is 61.43%\n",
      "Accuracy when k=5 on unfiltered data is 61.66%\n",
      "Accuracy when k=7 on unfiltered data is 60.99%\n",
      "Accuracy when k=10 on unfiltered data is 61.43%\n",
      "Accuracy when k=15 on unfiltered data is 58.07%\n",
      "Accuracy when k=20 on unfiltered data is 61.21%\n",
      "Elapsed time: 323.00 seconds\n"
     ]
    }
   ],
   "source": [
    "# Unfiltered data\n",
    "t0= time.time()\n",
    "k_vals = [1,3,5,7,10,15,20]\n",
    "for k in k_vals:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights = 'distance')\n",
    "    knn.fit(train_data, train_labels)\n",
    "    accuracy = knn.score(test_data, test_labels)*100\n",
    "    print(\"Accuracy when k=%s on unfiltered data is %.2f%%\" % (k,accuracy))\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"Elapsed time: %.2f seconds, or %.2f minutes\" % ((t1-t0), (t1-t0)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy when k=1 on unfiltered data is 58.74%\n",
      "Accuracy when k=3 on unfiltered data is 63.00%\n",
      "Accuracy when k=5 on unfiltered data is 59.42%\n",
      "Accuracy when k=7 on unfiltered data is 61.21%\n",
      "Accuracy when k=10 on unfiltered data is 62.33%\n",
      "Accuracy when k=15 on unfiltered data is 58.74%\n",
      "Accuracy when k=20 on unfiltered data is 63.45%\n",
      "Elapsed time: 324.69 seconds\n"
     ]
    }
   ],
   "source": [
    "# Filtered data\n",
    "t0= time.time()\n",
    "k_vals = [1,3,5,7,10,15,20]\n",
    "for k in k_vals:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights = 'distance')\n",
    "    knn.fit(train_data_f, train_labels)\n",
    "    accuracy = knn.score(test_data_f, test_labels)*100\n",
    "    print(\"Accuracy when k=%s on filtered data is %.2f%%\" % (k,accuracy))\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"Elapsed time: %.2f seconds, or %.2f minutes\" % ((t1-t0), (t1-t0)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "First without, then with laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on unfiltered data is 61.66%\n",
      "Accuracy on filtered data is 49.78%\n",
      "Elapsed time: 2.24 seconds\n"
     ]
    }
   ],
   "source": [
    "t0= time.time()\n",
    "\n",
    "# Fit model on unfiltered data\n",
    "nb_orig = BernoulliNB()\n",
    "nb_orig.fit(train_data, train_labels)\n",
    "accuracy = nb_orig.score(test_data, test_labels) *100\n",
    "print(\"Accuracy on unfiltered data is %.2f%%\" % accuracy_d)\n",
    "\n",
    "# Fit model on bilateral filtered data\n",
    "nb_filt = BernoulliNB()\n",
    "nb_filt.fit(train_data_f, train_labels)\n",
    "accuracy_f = nb_orig.score(test_data_f, test_labels) *100\n",
    "print(\"Accuracy on filtered data is %.2f%%\" % accuracy_f)\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"Elapsed time: %.2f seconds\" % (t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell makes Python ignore one of the useless warnings I was getting\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best alpha =  {'alpha': 1e-10}\n",
      "Elapsed time: 31.94 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "def LaPlace_alpha(alphas):\n",
    "    '''Tests various alphas to determine which one produces the best model.'''\n",
    "    \n",
    "    model = GridSearchCV(BernoulliNB(), alphas)\n",
    "    model.fit(train_data, train_labels)\n",
    "    return model.fit(train_data, train_labels)\n",
    "    \n",
    "\n",
    "alphas = {'alpha': [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "nb = LaPlace_alpha(alphas)\n",
    "print()\n",
    "print(\"Best alpha = \", nb.best_params_)\n",
    "t1 = time.time()\n",
    "print(\"Elapsed time: %.2f seconds\" % (t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As suspected, the smallest alpha (the least smoothed images) returns the best result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
